<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Rapternmn Blog</title>
    <link>https://rapternmn.github.io/</link>
    <description>Recent content on Rapternmn Blog</description>
    <generator>Hugo -- 0.152.2</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Nov 2025 19:56:11 +0530</lastBuildDate>
    <atom:link href="https://rapternmn.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Loss_functions</title>
      <link>https://rapternmn.github.io/posts/loss_functions/</link>
      <pubDate>Fri, 21 Nov 2025 19:56:11 +0530</pubDate>
      <guid>https://rapternmn.github.io/posts/loss_functions/</guid>
      <description>&lt;h1 id=&#34;-1-what-is-a-loss-function-high-level-overview&#34;&gt;üß† 1. What is a Loss Function? (High-Level Overview)&lt;/h1&gt;
&lt;p&gt;A loss function measures the difference between the model&amp;rsquo;s prediction and the ground truth.&lt;/p&gt;
&lt;p&gt;It answers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;‚û° How wrong is the model?&lt;/li&gt;
&lt;li&gt;‚û° In which direction should the parameters change?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;During training, optimization tries to minimize the loss by updating weights (using gradients).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loss ‚Üí Gradient ‚Üí Weight Update ‚Üí Better Predictions.&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#-1-what-is-a-loss-function-high-level-overview&#34;&gt;What is a Loss Function?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-2-why-do-we-need-loss-functions&#34;&gt;Why do we need Loss Functions?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-how-are-loss-functions-used-in-training&#34;&gt;How Are Loss Functions Used in Training?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-3-types-of-loss-functions-in-deep-learning&#34;&gt;Types of Loss Functions in Deep Learning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#-1-regression-losses&#34;&gt;Regression Losses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-2-classification-losses&#34;&gt;Classification Losses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-3-ranking--metric-learning-losses&#34;&gt;Ranking / Metric Learning Losses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-4-sequence-modeling-losses&#34;&gt;Sequence Modeling Losses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-5-image-losses&#34;&gt;Image Losses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-6-generative--autoencoder-losses&#34;&gt;Generative / Autoencoder Losses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-7-reinforcement-learning-losses&#34;&gt;Reinforcement Learning Losses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-8-autoencoder--reconstruction-losses&#34;&gt;Autoencoder &amp;amp; Reconstruction Losses&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#-summary-quick-reference-guide&#34;&gt;Summary: Quick Reference Guide&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-2-why-do-we-need-loss-functions&#34;&gt;üå≥ 2. Why do we need Loss Functions?&lt;/h2&gt;
&lt;h3 id=&#34;-they-quantify-model-error&#34;&gt;‚úîÔ∏è They quantify model error&lt;/h3&gt;
&lt;p&gt;Without a loss, we cannot measure how good or bad the model is.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
