<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Loss_functions | Rapternmn Blog</title><meta name=keywords content><meta name=description content="üß† 1. What is a Loss Function? (High-Level Overview)
A loss function measures the difference between the model&rsquo;s prediction and the ground truth.
It answers:

‚û° How wrong is the model?
‚û° In which direction should the parameters change?

During training, optimization tries to minimize the loss by updating weights (using gradients).
Loss ‚Üí Gradient ‚Üí Weight Update ‚Üí Better Predictions.

Table of Contents

What is a Loss Function?
Why do we need Loss Functions?
How Are Loss Functions Used in Training?
Types of Loss Functions in Deep Learning

Regression Losses
Classification Losses
Ranking / Metric Learning Losses
Sequence Modeling Losses
Image Losses
Generative / Autoencoder Losses
Reinforcement Learning Losses
Autoencoder & Reconstruction Losses


Summary: Quick Reference Guide


üå≥ 2. Why do we need Loss Functions?
‚úîÔ∏è They quantify model error
Without a loss, we cannot measure how good or bad the model is."><meta name=author content="Naman Bhayani"><link rel=canonical href=https://rapternmn.github.io/posts/loss_functions/><link crossorigin=anonymous href=https://rapternmn.github.io/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://rapternmn.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rapternmn.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rapternmn.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://rapternmn.github.io/apple-touch-icon.png><link rel=mask-icon href=https://rapternmn.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://rapternmn.github.io/posts/loss_functions/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://rapternmn.github.io/posts/loss_functions/"><meta property="og:site_name" content="Rapternmn Blog"><meta property="og:title" content="Loss_functions"><meta property="og:description" content="üß† 1. What is a Loss Function? (High-Level Overview) A loss function measures the difference between the model‚Äôs prediction and the ground truth.
It answers:
‚û° How wrong is the model? ‚û° In which direction should the parameters change? During training, optimization tries to minimize the loss by updating weights (using gradients).
Loss ‚Üí Gradient ‚Üí Weight Update ‚Üí Better Predictions.
Table of Contents What is a Loss Function? Why do we need Loss Functions? How Are Loss Functions Used in Training? Types of Loss Functions in Deep Learning Regression Losses Classification Losses Ranking / Metric Learning Losses Sequence Modeling Losses Image Losses Generative / Autoencoder Losses Reinforcement Learning Losses Autoencoder & Reconstruction Losses Summary: Quick Reference Guide üå≥ 2. Why do we need Loss Functions? ‚úîÔ∏è They quantify model error Without a loss, we cannot measure how good or bad the model is."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-21T19:56:11+05:30"><meta property="article:modified_time" content="2025-11-21T19:56:11+05:30"><meta name=twitter:card content="summary"><meta name=twitter:title content="Loss_functions"><meta name=twitter:description content="üß† 1. What is a Loss Function? (High-Level Overview)
A loss function measures the difference between the model&rsquo;s prediction and the ground truth.
It answers:

‚û° How wrong is the model?
‚û° In which direction should the parameters change?

During training, optimization tries to minimize the loss by updating weights (using gradients).
Loss ‚Üí Gradient ‚Üí Weight Update ‚Üí Better Predictions.

Table of Contents

What is a Loss Function?
Why do we need Loss Functions?
How Are Loss Functions Used in Training?
Types of Loss Functions in Deep Learning

Regression Losses
Classification Losses
Ranking / Metric Learning Losses
Sequence Modeling Losses
Image Losses
Generative / Autoencoder Losses
Reinforcement Learning Losses
Autoencoder & Reconstruction Losses


Summary: Quick Reference Guide


üå≥ 2. Why do we need Loss Functions?
‚úîÔ∏è They quantify model error
Without a loss, we cannot measure how good or bad the model is."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://rapternmn.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Loss_functions","item":"https://rapternmn.github.io/posts/loss_functions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Loss_functions","name":"Loss_functions","description":"üß† 1. What is a Loss Function? (High-Level Overview) A loss function measures the difference between the model\u0026rsquo;s prediction and the ground truth.\nIt answers:\n‚û° How wrong is the model? ‚û° In which direction should the parameters change? During training, optimization tries to minimize the loss by updating weights (using gradients).\nLoss ‚Üí Gradient ‚Üí Weight Update ‚Üí Better Predictions.\nTable of Contents What is a Loss Function? Why do we need Loss Functions? How Are Loss Functions Used in Training? Types of Loss Functions in Deep Learning Regression Losses Classification Losses Ranking / Metric Learning Losses Sequence Modeling Losses Image Losses Generative / Autoencoder Losses Reinforcement Learning Losses Autoencoder \u0026amp; Reconstruction Losses Summary: Quick Reference Guide üå≥ 2. Why do we need Loss Functions? ‚úîÔ∏è They quantify model error Without a loss, we cannot measure how good or bad the model is.\n","keywords":[],"articleBody":"üß† 1. What is a Loss Function? (High-Level Overview) A loss function measures the difference between the model‚Äôs prediction and the ground truth.\nIt answers:\n‚û° How wrong is the model? ‚û° In which direction should the parameters change? During training, optimization tries to minimize the loss by updating weights (using gradients).\nLoss ‚Üí Gradient ‚Üí Weight Update ‚Üí Better Predictions.\nTable of Contents What is a Loss Function? Why do we need Loss Functions? How Are Loss Functions Used in Training? Types of Loss Functions in Deep Learning Regression Losses Classification Losses Ranking / Metric Learning Losses Sequence Modeling Losses Image Losses Generative / Autoencoder Losses Reinforcement Learning Losses Autoencoder \u0026 Reconstruction Losses Summary: Quick Reference Guide üå≥ 2. Why do we need Loss Functions? ‚úîÔ∏è They quantify model error Without a loss, we cannot measure how good or bad the model is.\n‚úîÔ∏è They guide backpropagation The derivative of the loss tells each weight:\n‚ÄúIncrease or decrease to reduce error?‚Äù\n‚úîÔ∏è Different problems need different loss surfaces Example:\nClassification ‚Üí probability losses Regression ‚Üí distance losses Ranking ‚Üí pairwise or listwise losses Sequence ‚Üí token-level cross entropy Generative Models ‚Üí reconstruction losses, KL divergence, adversarial losses üß∞ How Are Loss Functions Used in Training? Training Loop:\nForward Pass: Take input x ‚Üí model predicts ≈∑ = f(x; Œ∏) Compute Loss: Calculate L(y, ≈∑) where y is ground truth Backward Pass: Compute gradients ‚àÇL/‚àÇŒ∏ using backpropagation Update Weights: Optimizer updates parameters: Œ∏ ‚Üê Œ∏ - Œ± * ‚àáL Repeat: Iterate over batches and epochs until convergence Key Components:\nLoss Function: Quantifies error Gradient: Direction of steepest increase in loss Optimizer: Algorithm to update weights (SGD, Adam, etc.) Learning Rate: Step size for weight updates Mathematical Formulation:\nŒ∏* = argmin_Œ∏ E[L(y, f(x; Œ∏))] The goal is to find parameters Œ∏ that minimize expected loss over the data distribution.\nüß© 3. Types of Loss Functions in Deep Learning We categorize them into 8 main groups.\nüü¶ 1. Regression Losses Used when predicting continuous values.\nMean Squared Error (MSE) Formula:\nL_MSE = (1/n) * Œ£(y_i - ≈∑_i)¬≤ Properties:\nPenalizes large errors more heavily (quadratic penalty) Differentiable everywhere Sensitive to outliers Gradient: ‚àÇL/‚àÇ≈∑ = -2(y - ≈∑) When to use:\nErrors are normally distributed Large errors should be heavily penalized Smooth gradients are needed Limitations:\nCan be dominated by outliers May converge slowly near the optimum Mean Absolute Error (MAE) Formula:\nL_MAE = (1/n) * Œ£|y_i - ≈∑_i| Properties:\nLinear penalty for all errors Robust to outliers Less sensitive to large errors than MSE Gradient: ‚àÇL/‚àÇ≈∑ = -sign(y - ≈∑) (not smooth at zero) When to use:\nOutliers are present in the data All errors should be treated equally Need robustness to noise Limitations:\nNot differentiable at zero May converge slower than MSE Huber Loss Formula:\nL_Huber = { (1/2) * (y - ≈∑)¬≤ if |y - ≈∑| ‚â§ Œ¥ Œ¥ * |y - ≈∑| - (1/2) * Œ¥¬≤ if |y - ≈∑| \u003e Œ¥ } Where Œ¥ (delta) is a hyperparameter (typically 1.0).\nProperties:\nCombines MSE (for small errors) and MAE (for large errors) Smooth and differentiable everywhere Robust to outliers like MAE Gradient: ‚àÇL/‚àÇ≈∑ = -(y - ≈∑) if |y - ≈∑| ‚â§ Œ¥ ‚àÇL/‚àÇ≈∑ = -Œ¥ * sign(y - ≈∑) if |y - ≈∑| \u003e Œ¥ When to use:\nWant balanced behavior between MSE and MAE Need smooth gradients but also robustness Common in robust regression tasks üü• 2. Classification Losses Used when predicting discrete labels.\nBinary Cross Entropy (BCE) Formula:\nL_BCE = -[y * log(p) + (1-y) * log(1-p)] For a batch of n samples:\nL_BCE = -(1/n) * Œ£[y_i * log(p_i) + (1-y_i) * log(1-p_i)] Properties:\nDerived from maximum likelihood estimation Works with sigmoid activation (outputs probabilities) Gradient: ‚àÇL/‚àÇp = -(y/p) + (1-y)/(1-p) = (p - y)/(p(1-p)) Well-suited for binary classification When to use:\nBinary classification problems Output layer uses sigmoid activation Need probabilistic outputs Note: Add epsilon (Œµ) to log arguments to avoid log(0) = -‚àû\nCategorical Cross Entropy (CCE) Formula:\nL_CCE = -Œ£(y_i * log(p_i)) For a batch:\nL_CCE = -(1/n) * Œ£ Œ£(y_ij * log(p_ij)) where i indexes samples and j indexes classes.\nProperties:\nRequires one-hot encoded labels Works with softmax activation Gradient: ‚àÇL/‚àÇp_i = -y_i/p_i Minimizes the KL divergence between true and predicted distributions When to use:\nMulti-class classification Output layer uses softmax activation Labels are one-hot encoded Sparse Categorical Cross Entropy Formula:\nL_Sparse_CCE = -log(p_k) where k is the true class index (integer label, not one-hot).\nProperties:\nSame as CCE but accepts integer labels instead of one-hot More memory efficient (no need to one-hot encode) Computationally equivalent to CCE When to use:\nMulti-class classification with integer labels Want to avoid one-hot encoding overhead Large number of classes (memory savings) Focal Loss Formula:\nFL = -Œ± * (1 - p_t)^Œ≥ * log(p_t) Where:\np_t = p if y = 1, else p_t = 1 - p Œ± (alpha) = weighting factor for rare class (typically 0.25) Œ≥ (gamma) = focusing parameter (typically 2.0) Properties:\nAddresses class imbalance by down-weighting easy examples (1 - p_t)^Œ≥ term reduces loss contribution from well-classified examples When Œ≥ = 0, reduces to standard cross-entropy Higher Œ≥ focuses more on hard examples When to use:\nHighly imbalanced datasets Object detection (many background vs few objects) Need to focus on hard-to-classify examples Example: In object detection, Œ≥=2 means easy negatives contribute 100x less to loss than hard examples.\nüü© 3. Ranking / Metric Learning Losses Used for retrieval, search, similarity tasks.\nContrastive Loss Formula:\nL_contrastive = { (1/2) * d¬≤ if y = 1 (similar) (1/2) * max(0, margin - d)¬≤ if y = 0 (dissimilar) } Where:\nd = ||f(x_a) - f(x_b)|| (distance between embeddings) margin = minimum distance for dissimilar pairs (hyperparameter, typically 1.0) Properties:\nPulls similar pairs together, pushes dissimilar pairs apart Used in Siamese networks Requires pairs of samples (similar/dissimilar labels) Gradient encourages embedding space separation When to use:\nLearning similarity metrics Siamese network architectures Face recognition, signature verification Need to learn meaningful embeddings Triplet Loss Formula:\nL_triplet = max(0, d(a,p) - d(a,n) + margin) Where:\na = anchor sample p = positive sample (same class as anchor) n = negative sample (different class from anchor) d(a,p) = distance between anchor and positive d(a,n) = distance between anchor and negative margin = minimum desired separation (typically 0.2-1.0) Properties:\nEnsures: d(a,p) + margin \u003c d(a,n) Requires triplets: (anchor, positive, negative) Used in FaceNet, person re-identification More efficient than contrastive (one loss per triplet vs two pairs) When to use:\nFace recognition (FaceNet) Person re-identification Learning embeddings where relative distances matter Need to ensure positive is closer than negative by margin Note: Hard negative mining is crucial - easy triplets contribute zero loss.\nPairwise Ranking / Hinge Loss Formula:\nL_hinge = max(0, margin - (s_pos - s_neg)) Where:\ns_pos = score for positive/relevant item s_neg = score for negative/irrelevant item margin = desired score difference (typically 1.0) Properties:\nUsed in Learning-to-Rank Encourages positive items to score higher than negatives Zero loss when score difference exceeds margin Common in recommendation systems, search ranking When to use:\nLearning-to-Rank problems Recommendation systems Search result ranking Need to order items by relevance üü™ 4. Sequence Modeling Losses Used in NLP, Transformers, LLMs.\nCross Entropy Loss (Token-level) Formula:\nL_CE = -(1/T) * Œ£ log(p(y_t | x_","wordCount":"2941","inLanguage":"en","datePublished":"2025-11-21T19:56:11+05:30","dateModified":"2025-11-21T19:56:11+05:30","author":{"@type":"Person","name":"Naman Bhayani"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://rapternmn.github.io/posts/loss_functions/"},"publisher":{"@type":"Organization","name":"Rapternmn Blog","logo":{"@type":"ImageObject","url":"https://rapternmn.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://rapternmn.github.io/ accesskey=h title="Rapternmn Blog (Alt + H)">Rapternmn Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rapternmn.github.io/about/ title=About><span>About</span></a></li><li><a href=https://rapternmn.github.io/posts/ title=Posts><span>Posts</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Loss_functions</h1><div class=post-meta><span title='2025-11-21 19:56:11 +0530 IST'>November 21, 2025</span>&nbsp;¬∑&nbsp;<span>14 min</span>&nbsp;¬∑&nbsp;<span>Naman Bhayani</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#-1-what-is-a-loss-function-high-level-overview aria-label="üß† 1. What is a Loss Function? (High-Level Overview)">üß† 1. What is a Loss Function? (High-Level Overview)</a><ul><li><a href=#table-of-contents aria-label="Table of Contents">Table of Contents</a></li><li><a href=#-2-why-do-we-need-loss-functions aria-label="üå≥ 2. Why do we need Loss Functions?">üå≥ 2. Why do we need Loss Functions?</a><ul><li><a href=#-they-quantify-model-error aria-label="‚úîÔ∏è They quantify model error">‚úîÔ∏è They quantify model error</a></li><li><a href=#-they-guide-backpropagation aria-label="‚úîÔ∏è They guide backpropagation">‚úîÔ∏è They guide backpropagation</a></li><li><a href=#-different-problems-need-different-loss-surfaces aria-label="‚úîÔ∏è Different problems need different loss surfaces">‚úîÔ∏è Different problems need different loss surfaces</a></li></ul></li><li><a href=#-how-are-loss-functions-used-in-training aria-label="üß∞ How Are Loss Functions Used in Training?">üß∞ How Are Loss Functions Used in Training?</a></li><li><a href=#-3-types-of-loss-functions-in-deep-learning aria-label="üß© 3. Types of Loss Functions in Deep Learning">üß© 3. Types of Loss Functions in Deep Learning</a><ul><li><a href=#-1-regression-losses aria-label="üü¶ 1. Regression Losses">üü¶ 1. Regression Losses</a><ul><li><a href=#mean-squared-error-mse aria-label="Mean Squared Error (MSE)">Mean Squared Error (MSE)</a></li><li><a href=#mean-absolute-error-mae aria-label="Mean Absolute Error (MAE)">Mean Absolute Error (MAE)</a></li><li><a href=#huber-loss aria-label="Huber Loss">Huber Loss</a></li></ul></li><li><a href=#-2-classification-losses aria-label="üü• 2. Classification Losses">üü• 2. Classification Losses</a><ul><li><a href=#binary-cross-entropy-bce aria-label="Binary Cross Entropy (BCE)">Binary Cross Entropy (BCE)</a></li><li><a href=#categorical-cross-entropy-cce aria-label="Categorical Cross Entropy (CCE)">Categorical Cross Entropy (CCE)</a></li><li><a href=#sparse-categorical-cross-entropy aria-label="Sparse Categorical Cross Entropy">Sparse Categorical Cross Entropy</a></li><li><a href=#focal-loss aria-label="Focal Loss">Focal Loss</a></li></ul></li><li><a href=#-3-ranking--metric-learning-losses aria-label="üü© 3. Ranking / Metric Learning Losses">üü© 3. Ranking / Metric Learning Losses</a><ul><li><a href=#contrastive-loss aria-label="Contrastive Loss">Contrastive Loss</a></li><li><a href=#triplet-loss aria-label="Triplet Loss">Triplet Loss</a></li><li><a href=#pairwise-ranking--hinge-loss aria-label="Pairwise Ranking / Hinge Loss">Pairwise Ranking / Hinge Loss</a></li></ul></li><li><a href=#-4-sequence-modeling-losses aria-label="üü™ 4. Sequence Modeling Losses">üü™ 4. Sequence Modeling Losses</a><ul><li><a href=#cross-entropy-loss-token-level aria-label="Cross Entropy Loss (Token-level)">Cross Entropy Loss (Token-level)</a></li><li><a href=#label-smoothing-loss aria-label="Label Smoothing Loss">Label Smoothing Loss</a></li><li><a href=#kl-divergence aria-label="KL Divergence">KL Divergence</a></li></ul></li><li><a href=#-5-image-losses aria-label="üü´ 5. Image Losses">üü´ 5. Image Losses</a><ul><li><a href=#dice-loss aria-label="Dice Loss">Dice Loss</a></li><li><a href=#iou-loss-jaccard-loss aria-label="IoU Loss (Jaccard Loss)">IoU Loss (Jaccard Loss)</a></li><li><a href=#combined-losses-bce--dice--bce--iou aria-label="Combined Losses: BCE + Dice / BCE + IoU">Combined Losses: BCE + Dice / BCE + IoU</a></li></ul></li><li><a href=#-6-generative--autoencoder-losses aria-label="üüß 6. Generative / Autoencoder Losses">üüß 6. Generative / Autoencoder Losses</a><ul><li><a href=#minimax-loss-original-gan aria-label="Minimax Loss (Original GAN)">Minimax Loss (Original GAN)</a></li><li><a href=#least-squares-gan-lsgan aria-label="Least Squares GAN (LSGAN)">Least Squares GAN (LSGAN)</a></li><li><a href=#wasserstein-loss-wgan aria-label="Wasserstein Loss (WGAN)">Wasserstein Loss (WGAN)</a></li></ul></li><li><a href=#-7-reinforcement-learning-losses aria-label="üü® 7. Reinforcement Learning Losses">üü® 7. Reinforcement Learning Losses</a><ul><li><a href=#policy-gradient-loss-reinforce aria-label="Policy Gradient Loss (REINFORCE)">Policy Gradient Loss (REINFORCE)</a></li><li><a href=#value-function-loss aria-label="Value Function Loss">Value Function Loss</a></li><li><a href=#ppo-loss-clipped aria-label="PPO Loss (Clipped)">PPO Loss (Clipped)</a></li></ul></li><li><a href=#-8-autoencoder--reconstruction-losses aria-label="üü© 8. Autoencoder & Reconstruction Losses">üü© 8. Autoencoder & Reconstruction Losses</a><ul><li><a href=#81-reconstruction-loss aria-label="8.1 Reconstruction Loss">8.1 Reconstruction Loss</a></li><li><a href=#82-kl-divergence-vae aria-label="8.2 KL Divergence (VAE)">8.2 KL Divergence (VAE)</a></li></ul></li></ul></li><li><a href=#-summary-quick-reference-guide aria-label="üìä Summary: Quick Reference Guide">üìä Summary: Quick Reference Guide</a><ul><li><a href=#loss-function-selection-by-task aria-label="Loss Function Selection by Task">Loss Function Selection by Task</a></li><li><a href=#key-properties-to-consider aria-label="Key Properties to Consider">Key Properties to Consider</a></li><li><a href=#common-patterns aria-label="Common Patterns">Common Patterns</a></li><li><a href=#best-practices aria-label="Best Practices">Best Practices</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><h1 id=-1-what-is-a-loss-function-high-level-overview>üß† 1. What is a Loss Function? (High-Level Overview)<a hidden class=anchor aria-hidden=true href=#-1-what-is-a-loss-function-high-level-overview>#</a></h1><p>A loss function measures the difference between the model&rsquo;s prediction and the ground truth.</p><p>It answers:</p><ul><li>‚û° How wrong is the model?</li><li>‚û° In which direction should the parameters change?</li></ul><p>During training, optimization tries to minimize the loss by updating weights (using gradients).</p><p><strong>Loss ‚Üí Gradient ‚Üí Weight Update ‚Üí Better Predictions.</strong></p><hr><h2 id=table-of-contents>Table of Contents<a hidden class=anchor aria-hidden=true href=#table-of-contents>#</a></h2><ol><li><a href=#-1-what-is-a-loss-function-high-level-overview>What is a Loss Function?</a></li><li><a href=#-2-why-do-we-need-loss-functions>Why do we need Loss Functions?</a></li><li><a href=#-how-are-loss-functions-used-in-training>How Are Loss Functions Used in Training?</a></li><li><a href=#-3-types-of-loss-functions-in-deep-learning>Types of Loss Functions in Deep Learning</a><ul><li><a href=#-1-regression-losses>Regression Losses</a></li><li><a href=#-2-classification-losses>Classification Losses</a></li><li><a href=#-3-ranking--metric-learning-losses>Ranking / Metric Learning Losses</a></li><li><a href=#-4-sequence-modeling-losses>Sequence Modeling Losses</a></li><li><a href=#-5-image-losses>Image Losses</a></li><li><a href=#-6-generative--autoencoder-losses>Generative / Autoencoder Losses</a></li><li><a href=#-7-reinforcement-learning-losses>Reinforcement Learning Losses</a></li><li><a href=#-8-autoencoder--reconstruction-losses>Autoencoder & Reconstruction Losses</a></li></ul></li><li><a href=#-summary-quick-reference-guide>Summary: Quick Reference Guide</a></li></ol><hr><h2 id=-2-why-do-we-need-loss-functions>üå≥ 2. Why do we need Loss Functions?<a hidden class=anchor aria-hidden=true href=#-2-why-do-we-need-loss-functions>#</a></h2><h3 id=-they-quantify-model-error>‚úîÔ∏è They quantify model error<a hidden class=anchor aria-hidden=true href=#-they-quantify-model-error>#</a></h3><p>Without a loss, we cannot measure how good or bad the model is.</p><h3 id=-they-guide-backpropagation>‚úîÔ∏è They guide backpropagation<a hidden class=anchor aria-hidden=true href=#-they-guide-backpropagation>#</a></h3><p>The derivative of the loss tells each weight:</p><blockquote><p>&ldquo;Increase or decrease to reduce error?&rdquo;</p></blockquote><h3 id=-different-problems-need-different-loss-surfaces>‚úîÔ∏è Different problems need different loss surfaces<a hidden class=anchor aria-hidden=true href=#-different-problems-need-different-loss-surfaces>#</a></h3><p><strong>Example:</strong></p><ul><li><strong>Classification</strong> ‚Üí probability losses</li><li><strong>Regression</strong> ‚Üí distance losses</li><li><strong>Ranking</strong> ‚Üí pairwise or listwise losses</li><li><strong>Sequence</strong> ‚Üí token-level cross entropy</li><li><strong>Generative Models</strong> ‚Üí reconstruction losses, KL divergence, adversarial losses</li></ul><hr><h2 id=-how-are-loss-functions-used-in-training>üß∞ How Are Loss Functions Used in Training?<a hidden class=anchor aria-hidden=true href=#-how-are-loss-functions-used-in-training>#</a></h2><p><strong>Training Loop:</strong></p><ol><li><strong>Forward Pass:</strong> Take input <code>x</code> ‚Üí model predicts <code>≈∑ = f(x; Œ∏)</code></li><li><strong>Compute Loss:</strong> Calculate <code>L(y, ≈∑)</code> where <code>y</code> is ground truth</li><li><strong>Backward Pass:</strong> Compute gradients <code>‚àÇL/‚àÇŒ∏</code> using backpropagation</li><li><strong>Update Weights:</strong> Optimizer updates parameters: <code>Œ∏ ‚Üê Œ∏ - Œ± * ‚àáL</code></li><li><strong>Repeat:</strong> Iterate over batches and epochs until convergence</li></ol><p><strong>Key Components:</strong></p><ul><li><strong>Loss Function:</strong> Quantifies error</li><li><strong>Gradient:</strong> Direction of steepest increase in loss</li><li><strong>Optimizer:</strong> Algorithm to update weights (SGD, Adam, etc.)</li><li><strong>Learning Rate:</strong> Step size for weight updates</li></ul><p><strong>Mathematical Formulation:</strong></p><pre tabindex=0><code>Œ∏* = argmin_Œ∏ E[L(y, f(x; Œ∏))]
</code></pre><p>The goal is to find parameters <code>Œ∏</code> that minimize expected loss over the data distribution.</p><hr><h2 id=-3-types-of-loss-functions-in-deep-learning>üß© 3. Types of Loss Functions in Deep Learning<a hidden class=anchor aria-hidden=true href=#-3-types-of-loss-functions-in-deep-learning>#</a></h2><p>We categorize them into 8 main groups.</p><h3 id=-1-regression-losses>üü¶ 1. Regression Losses<a hidden class=anchor aria-hidden=true href=#-1-regression-losses>#</a></h3><p>Used when predicting continuous values.</p><h4 id=mean-squared-error-mse>Mean Squared Error (MSE)<a hidden class=anchor aria-hidden=true href=#mean-squared-error-mse>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_MSE = (1/n) * Œ£(y_i - ≈∑_i)¬≤
</code></pre><p><strong>Properties:</strong></p><ul><li>Penalizes large errors more heavily (quadratic penalty)</li><li>Differentiable everywhere</li><li>Sensitive to outliers</li><li>Gradient: <code>‚àÇL/‚àÇ≈∑ = -2(y - ≈∑)</code></li></ul><p><strong>When to use:</strong></p><ul><li>Errors are normally distributed</li><li>Large errors should be heavily penalized</li><li>Smooth gradients are needed</li></ul><p><strong>Limitations:</strong></p><ul><li>Can be dominated by outliers</li><li>May converge slowly near the optimum</li></ul><hr><h4 id=mean-absolute-error-mae>Mean Absolute Error (MAE)<a hidden class=anchor aria-hidden=true href=#mean-absolute-error-mae>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_MAE = (1/n) * Œ£|y_i - ≈∑_i|
</code></pre><p><strong>Properties:</strong></p><ul><li>Linear penalty for all errors</li><li>Robust to outliers</li><li>Less sensitive to large errors than MSE</li><li>Gradient: <code>‚àÇL/‚àÇ≈∑ = -sign(y - ≈∑)</code> (not smooth at zero)</li></ul><p><strong>When to use:</strong></p><ul><li>Outliers are present in the data</li><li>All errors should be treated equally</li><li>Need robustness to noise</li></ul><p><strong>Limitations:</strong></p><ul><li>Not differentiable at zero</li><li>May converge slower than MSE</li></ul><hr><h4 id=huber-loss>Huber Loss<a hidden class=anchor aria-hidden=true href=#huber-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_Huber = {
    (1/2) * (y - ≈∑)¬≤          if |y - ≈∑| ‚â§ Œ¥
    Œ¥ * |y - ≈∑| - (1/2) * Œ¥¬≤  if |y - ≈∑| &gt; Œ¥
}
</code></pre><p>Where <code>Œ¥</code> (delta) is a hyperparameter (typically <code>1.0</code>).</p><p><strong>Properties:</strong></p><ul><li>Combines MSE (for small errors) and MAE (for large errors)</li><li>Smooth and differentiable everywhere</li><li>Robust to outliers like MAE</li><li>Gradient:<ul><li><code>‚àÇL/‚àÇ≈∑ = -(y - ≈∑)</code> if <code>|y - ≈∑| ‚â§ Œ¥</code></li><li><code>‚àÇL/‚àÇ≈∑ = -Œ¥ * sign(y - ≈∑)</code> if <code>|y - ≈∑| > Œ¥</code></li></ul></li></ul><p><strong>When to use:</strong></p><ul><li>Want balanced behavior between MSE and MAE</li><li>Need smooth gradients but also robustness</li><li>Common in robust regression tasks</li></ul><hr><h3 id=-2-classification-losses>üü• 2. Classification Losses<a hidden class=anchor aria-hidden=true href=#-2-classification-losses>#</a></h3><p>Used when predicting discrete labels.</p><h4 id=binary-cross-entropy-bce>Binary Cross Entropy (BCE)<a hidden class=anchor aria-hidden=true href=#binary-cross-entropy-bce>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_BCE = -[y * log(p) + (1-y) * log(1-p)]
</code></pre><p>For a batch of n samples:</p><pre tabindex=0><code>L_BCE = -(1/n) * Œ£[y_i * log(p_i) + (1-y_i) * log(1-p_i)]
</code></pre><p><strong>Properties:</strong></p><ul><li>Derived from maximum likelihood estimation</li><li>Works with sigmoid activation (outputs probabilities)</li><li>Gradient: <code>‚àÇL/‚àÇp = -(y/p) + (1-y)/(1-p) = (p - y)/(p(1-p))</code></li><li>Well-suited for binary classification</li></ul><p><strong>When to use:</strong></p><ul><li>Binary classification problems</li><li>Output layer uses sigmoid activation</li><li>Need probabilistic outputs</li></ul><p><strong>Note:</strong> Add epsilon (<code>Œµ</code>) to log arguments to avoid <code>log(0) = -‚àû</code></p><hr><h4 id=categorical-cross-entropy-cce>Categorical Cross Entropy (CCE)<a hidden class=anchor aria-hidden=true href=#categorical-cross-entropy-cce>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_CCE = -Œ£(y_i * log(p_i))
</code></pre><p>For a batch:</p><pre tabindex=0><code>L_CCE = -(1/n) * Œ£ Œ£(y_ij * log(p_ij))
</code></pre><p>where <code>i</code> indexes samples and <code>j</code> indexes classes.</p><p><strong>Properties:</strong></p><ul><li>Requires one-hot encoded labels</li><li>Works with softmax activation</li><li>Gradient: <code>‚àÇL/‚àÇp_i = -y_i/p_i</code></li><li>Minimizes the KL divergence between true and predicted distributions</li></ul><p><strong>When to use:</strong></p><ul><li>Multi-class classification</li><li>Output layer uses softmax activation</li><li>Labels are one-hot encoded</li></ul><hr><h4 id=sparse-categorical-cross-entropy>Sparse Categorical Cross Entropy<a hidden class=anchor aria-hidden=true href=#sparse-categorical-cross-entropy>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_Sparse_CCE = -log(p_k)
</code></pre><p>where <code>k</code> is the true class index (integer label, not one-hot).</p><p><strong>Properties:</strong></p><ul><li>Same as CCE but accepts integer labels instead of one-hot</li><li>More memory efficient (no need to one-hot encode)</li><li>Computationally equivalent to CCE</li></ul><p><strong>When to use:</strong></p><ul><li>Multi-class classification with integer labels</li><li>Want to avoid one-hot encoding overhead</li><li>Large number of classes (memory savings)</li></ul><hr><h4 id=focal-loss>Focal Loss<a hidden class=anchor aria-hidden=true href=#focal-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>FL = -Œ± * (1 - p_t)^Œ≥ * log(p_t)
</code></pre><p>Where:</p><ul><li><code>p_t = p</code> if <code>y = 1</code>, else <code>p_t = 1 - p</code></li><li><code>Œ±</code> (alpha) = weighting factor for rare class (typically <code>0.25</code>)</li><li><code>Œ≥</code> (gamma) = focusing parameter (typically <code>2.0</code>)</li></ul><p><strong>Properties:</strong></p><ul><li>Addresses class imbalance by down-weighting easy examples</li><li><code>(1 - p_t)^Œ≥</code> term reduces loss contribution from well-classified examples</li><li>When <code>Œ≥ = 0</code>, reduces to standard cross-entropy</li><li>Higher <code>Œ≥</code> focuses more on hard examples</li></ul><p><strong>When to use:</strong></p><ul><li>Highly imbalanced datasets</li><li>Object detection (many background vs few objects)</li><li>Need to focus on hard-to-classify examples</li></ul><p><strong>Example:</strong> In object detection, <code>Œ≥=2</code> means easy negatives contribute <code>100x</code> less to loss than hard examples.</p><hr><h3 id=-3-ranking--metric-learning-losses>üü© 3. Ranking / Metric Learning Losses<a hidden class=anchor aria-hidden=true href=#-3-ranking--metric-learning-losses>#</a></h3><p>Used for retrieval, search, similarity tasks.</p><h4 id=contrastive-loss>Contrastive Loss<a hidden class=anchor aria-hidden=true href=#contrastive-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_contrastive = {
    (1/2) * d¬≤                    if y = 1 (similar)
    (1/2) * max(0, margin - d)¬≤   if y = 0 (dissimilar)
}
</code></pre><p>Where:</p><ul><li><code>d = ||f(x_a) - f(x_b)||</code> (distance between embeddings)</li><li><code>margin</code> = minimum distance for dissimilar pairs (hyperparameter, typically <code>1.0</code>)</li></ul><p><strong>Properties:</strong></p><ul><li>Pulls similar pairs together, pushes dissimilar pairs apart</li><li>Used in Siamese networks</li><li>Requires pairs of samples (similar/dissimilar labels)</li><li>Gradient encourages embedding space separation</li></ul><p><strong>When to use:</strong></p><ul><li>Learning similarity metrics</li><li>Siamese network architectures</li><li>Face recognition, signature verification</li><li>Need to learn meaningful embeddings</li></ul><hr><h4 id=triplet-loss>Triplet Loss<a hidden class=anchor aria-hidden=true href=#triplet-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_triplet = max(0, d(a,p) - d(a,n) + margin)
</code></pre><p>Where:</p><ul><li><code>a</code> = anchor sample</li><li><code>p</code> = positive sample (same class as anchor)</li><li><code>n</code> = negative sample (different class from anchor)</li><li><code>d(a,p)</code> = distance between anchor and positive</li><li><code>d(a,n)</code> = distance between anchor and negative</li><li><code>margin</code> = minimum desired separation (typically <code>0.2-1.0</code>)</li></ul><p><strong>Properties:</strong></p><ul><li>Ensures: <code>d(a,p) + margin &lt; d(a,n)</code></li><li>Requires triplets: (anchor, positive, negative)</li><li>Used in FaceNet, person re-identification</li><li>More efficient than contrastive (one loss per triplet vs two pairs)</li></ul><p><strong>When to use:</strong></p><ul><li>Face recognition (FaceNet)</li><li>Person re-identification</li><li>Learning embeddings where relative distances matter</li><li>Need to ensure positive is closer than negative by margin</li></ul><p><strong>Note:</strong> Hard negative mining is crucial - easy triplets contribute zero loss.</p><hr><h4 id=pairwise-ranking--hinge-loss>Pairwise Ranking / Hinge Loss<a hidden class=anchor aria-hidden=true href=#pairwise-ranking--hinge-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_hinge = max(0, margin - (s_pos - s_neg))
</code></pre><p>Where:</p><ul><li><code>s_pos</code> = score for positive/relevant item</li><li><code>s_neg</code> = score for negative/irrelevant item</li><li><code>margin</code> = desired score difference (typically <code>1.0</code>)</li></ul><p><strong>Properties:</strong></p><ul><li>Used in Learning-to-Rank</li><li>Encourages positive items to score higher than negatives</li><li>Zero loss when score difference exceeds margin</li><li>Common in recommendation systems, search ranking</li></ul><p><strong>When to use:</strong></p><ul><li>Learning-to-Rank problems</li><li>Recommendation systems</li><li>Search result ranking</li><li>Need to order items by relevance</li></ul><hr><h3 id=-4-sequence-modeling-losses>üü™ 4. Sequence Modeling Losses<a hidden class=anchor aria-hidden=true href=#-4-sequence-modeling-losses>#</a></h3><p>Used in NLP, Transformers, LLMs.</p><h4 id=cross-entropy-loss-token-level>Cross Entropy Loss (Token-level)<a hidden class=anchor aria-hidden=true href=#cross-entropy-loss-token-level>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_CE = -(1/T) * Œ£ log(p(y_t | x_&lt;t))
</code></pre><p>Where:</p><ul><li><code>T</code> = sequence length</li><li><code>y_t</code> = true token at position <code>t</code></li><li><code>x_&lt;t</code> = context up to position <code>t</code></li></ul><p><strong>Properties:</strong></p><ul><li>Standard loss for language modeling</li><li>Applied per token in sequence</li><li>Used in GPT, BERT, T5, translation models</li><li>Same as categorical cross-entropy but applied token-wise</li></ul><p><strong>When to use:</strong></p><ul><li>Language modeling (next token prediction)</li><li>Machine translation</li><li>Text generation</li><li>Any autoregressive sequence model</li></ul><p><strong>Note:</strong> Often combined with teacher forcing during training.</p><hr><h4 id=label-smoothing-loss>Label Smoothing Loss<a hidden class=anchor aria-hidden=true href=#label-smoothing-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_smooth = -(1/T) * Œ£ [y_t * log(p_t) + (1-y_t) * log(1-p_t)]
</code></pre><p>Where the true distribution is modified:</p><ul><li>Hard labels: <code>y_t = 1</code> for true class, <code>0</code> otherwise</li><li>Smoothed labels: <code>y_t = (1 - Œ±)</code> for true class, <code>Œ±/(K-1)</code> for others</li><li><code>Œ±</code> = smoothing factor (typically <code>0.1</code>)</li><li><code>K</code> = number of classes</li></ul><p><strong>Properties:</strong></p><ul><li>Prevents overconfidence (logits don&rsquo;t become too extreme)</li><li>Regularization effect</li><li>Improves generalization</li><li>Used in BERT, GPT-2, many modern LLMs</li></ul><p><strong>When to use:</strong></p><ul><li>Models becoming overconfident</li><li>Need better calibration</li><li>Want regularization without dropout</li><li>Large language models</li></ul><p><strong>Example:</strong> With <code>Œ±=0.1</code> and <code>K=1000</code>, true class gets <code>0.9</code>, others get <code>0.1/999 ‚âà 0.0001</code></p><hr><h4 id=kl-divergence>KL Divergence<a hidden class=anchor aria-hidden=true href=#kl-divergence>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>KL(P || Q) = Œ£ P(x) * log(P(x) / Q(x))
</code></pre><p>For continuous distributions:</p><pre tabindex=0><code>KL(P || Q) = ‚à´ p(x) * log(p(x) / q(x)) dx
</code></pre><p><strong>Properties:</strong></p><ul><li>Measures difference between two probability distributions</li><li>Asymmetric: <code>KL(P||Q) ‚â† KL(Q||P)</code></li><li>Always non-negative, zero when <code>P = Q</code></li><li>Used in VAEs (regularization term) and knowledge distillation</li></ul><p><strong>When to use:</strong></p><ul><li><strong>VAEs:</strong> Regularize latent space to match prior (typically N(0,1))</li><li><strong>Knowledge Distillation:</strong> Match student to teacher distribution</li><li><strong>Variational inference:</strong> Approximate posterior to prior</li></ul><p><strong>VAE Example:</strong></p><pre tabindex=0><code>L_VAE = Reconstruction_Loss + Œ≤ * KL(q(z|x) || p(z))
</code></pre><p>where <code>Œ≤</code> controls regularization strength (Œ≤-VAE).</p><hr><h3 id=-5-image-losses>üü´ 5. Image Losses<a hidden class=anchor aria-hidden=true href=#-5-image-losses>#</a></h3><h4 id=dice-loss>Dice Loss<a hidden class=anchor aria-hidden=true href=#dice-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>Dice_Score = (2 * |X ‚à© Y|) / (|X| + |Y|)
Dice_Loss = 1 - Dice_Score
</code></pre><p>In terms of predictions and ground truth:</p><pre tabindex=0><code>Dice_Loss = 1 - (2 * Œ£(p_i * y_i) + Œµ) / (Œ£(p_i) + Œ£(y_i) + Œµ)
</code></pre><p>Where:</p><ul><li><code>p_i</code> = predicted probability for pixel <code>i</code></li><li><code>y_i</code> = ground truth label for pixel <code>i</code> (<code>0</code> or <code>1</code>)</li><li><code>Œµ</code> = small constant to avoid division by zero (typically <code>1e-5</code>)</li></ul><p><strong>Properties:</strong></p><ul><li>Measures overlap between predicted and true masks</li><li>Range: [0, 1], where 0 = perfect overlap</li><li>Handles class imbalance well (focuses on foreground)</li><li>Differentiable approximation of Dice coefficient</li></ul><p><strong>When to use:</strong></p><ul><li>Medical image segmentation</li><li>Imbalanced segmentation tasks (small objects)</li><li>UNet, DeepLab architectures</li><li>When IoU is the evaluation metric</li></ul><p><strong>Advantages:</strong></p><ul><li>Less sensitive to class imbalance than BCE</li><li>Directly optimizes overlap metric</li></ul><hr><h4 id=iou-loss-jaccard-loss>IoU Loss (Jaccard Loss)<a hidden class=anchor aria-hidden=true href=#iou-loss-jaccard-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>IoU = |X ‚à© Y| / |X ‚à™ Y|
IoU_Loss = 1 - IoU
</code></pre><p>In terms of predictions:</p><pre tabindex=0><code>IoU_Loss = 1 - (Œ£(p_i * y_i) + Œµ) / (Œ£(p_i + y_i - p_i * y_i) + Œµ)
</code></pre><p><strong>Properties:</strong></p><ul><li>Intersection over Union metric</li><li>Range: [0, 1]</li><li>Standard evaluation metric for segmentation</li><li>Penalizes both false positives and false negatives</li></ul><p><strong>When to use:</strong></p><ul><li>Segmentation tasks where IoU is the evaluation metric</li><li>Need to directly optimize IoU</li><li>Object detection (bounding box IoU)</li></ul><p><strong>Comparison with Dice:</strong></p><ul><li>IoU is more strict (penalizes more for errors)</li><li>Dice is more forgiving for small errors</li><li>Both handle class imbalance</li></ul><hr><h4 id=combined-losses-bce--dice--bce--iou>Combined Losses: BCE + Dice / BCE + IoU<a hidden class=anchor aria-hidden=true href=#combined-losses-bce--dice--bce--iou>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_combined = Œ± * L_BCE + (1 - Œ±) * L_Dice
</code></pre><p>Or:</p><pre tabindex=0><code>L_combined = Œ± * L_BCE + (1 - Œ±) * L_IoU
</code></pre><p>Where <code>Œ±</code> is a weighting factor (typically <code>0.5</code>).</p><p><strong>Properties:</strong></p><ul><li>Combines pixel-wise (BCE) and region-wise (Dice/IoU) losses</li><li>BCE provides stable gradients</li><li>Dice/IoU directly optimizes overlap metric</li><li>Common in UNet, DeepLab, and modern segmentation models</li></ul><p><strong>When to use:</strong></p><ul><li>Medical image segmentation</li><li>UNet-based architectures</li><li>Want benefits of both losses</li><li>Need stable training with direct metric optimization</li></ul><p><strong>Typical values:</strong> <code>Œ± = 0.5</code> (equal weighting) or <code>Œ± = 0.7</code> (more weight on BCE)</p><hr><h3 id=-6-generative--autoencoder-losses>üüß 6. Generative / Autoencoder Losses<a hidden class=anchor aria-hidden=true href=#-6-generative--autoencoder-losses>#</a></h3><h4 id=minimax-loss-original-gan>Minimax Loss (Original GAN)<a hidden class=anchor aria-hidden=true href=#minimax-loss-original-gan>#</a></h4><p><strong>Formula:</strong></p><p><strong>Generator Loss:</strong></p><pre tabindex=0><code>L_G = -E[log(D(G(z)))]
</code></pre><p><strong>Discriminator Loss:</strong></p><pre tabindex=0><code>L_D = -E[log(D(x))] - E[log(1 - D(G(z)))]
</code></pre><p>Where:</p><ul><li><code>D(x)</code> = discriminator output for real data</li><li><code>G(z)</code> = generator output from noise <code>z</code></li><li><code>D(G(z))</code> = discriminator output for fake data</li></ul><p><strong>Properties:</strong></p><ul><li>Two-player minimax game</li><li>Generator tries to fool discriminator</li><li>Discriminator tries to distinguish real from fake</li><li>Training can be unstable (vanishing gradients)</li></ul><p><strong>When to use:</strong></p><ul><li>Original GAN formulation</li><li>Understanding GAN fundamentals</li><li>Not recommended for production (use improved versions)</li></ul><p><strong>Issues:</strong></p><ul><li>Vanishing gradients when discriminator is too good</li><li>Mode collapse (generator produces limited diversity)</li><li>Training instability</li></ul><hr><h4 id=least-squares-gan-lsgan>Least Squares GAN (LSGAN)<a hidden class=anchor aria-hidden=true href=#least-squares-gan-lsgan>#</a></h4><p><strong>Formula:</strong></p><p><strong>Generator Loss:</strong></p><pre tabindex=0><code>L_G = (1/2) * E[(D(G(z)) - 1)¬≤]
</code></pre><p><strong>Discriminator Loss:</strong></p><pre tabindex=0><code>L_D = (1/2) * E[(D(x) - 1)¬≤] + (1/2) * E[D(G(z))¬≤]
</code></pre><p><strong>Properties:</strong></p><ul><li>Uses L2 loss instead of cross-entropy</li><li>More stable gradients</li><li>Penalizes samples far from decision boundary</li><li>Reduces mode collapse compared to original GAN</li></ul><p><strong>When to use:</strong></p><ul><li>Need more stable GAN training</li><li>Want to avoid vanishing gradients</li><li>Image generation tasks</li></ul><p><strong>Advantages:</strong></p><ul><li>Smoother loss landscape</li><li>Better gradient flow</li><li>More stable training</li></ul><hr><h4 id=wasserstein-loss-wgan>Wasserstein Loss (WGAN)<a hidden class=anchor aria-hidden=true href=#wasserstein-loss-wgan>#</a></h4><p><strong>Formula:</strong></p><p><strong>Generator Loss:</strong></p><pre tabindex=0><code>L_G = -E[D(G(z))]
</code></pre><p><strong>Discriminator Loss (Critic):</strong></p><pre tabindex=0><code>L_D = E[D(G(z))] - E[D(x)]
</code></pre><p>With gradient penalty (WGAN-GP):</p><pre tabindex=0><code>L_D = E[D(G(z))] - E[D(x)] + Œª * E[(||‚àáD(xÃÇ)|| - 1)¬≤]
</code></pre><p>Where:</p><ul><li><code>xÃÇ</code> = random interpolation between real and fake samples</li><li><code>Œª</code> = gradient penalty weight (typically <code>10</code>)</li><li>Discriminator (called &ldquo;critic&rdquo;) must be <code>1-Lipschitz</code></li></ul><p><strong>Properties:</strong></p><ul><li>Measures Wasserstein-1 distance (Earth Mover&rsquo;s Distance)</li><li>Provides meaningful training signal even when discriminator is optimal</li><li>More stable than original GAN</li><li>Requires weight clipping (WGAN) or gradient penalty (WGAN-GP)</li></ul><p><strong>When to use:</strong></p><ul><li>Need stable GAN training</li><li>Want to avoid mode collapse</li><li>Image generation, style transfer</li><li>When discriminator accuracy is not meaningful</li></ul><p><strong>Advantages:</strong></p><ul><li>Stable gradients throughout training</li><li>Meaningful loss value (correlates with sample quality)</li><li>Less mode collapse</li><li>Better convergence properties</li></ul><hr><h3 id=-7-reinforcement-learning-losses>üü® 7. Reinforcement Learning Losses<a hidden class=anchor aria-hidden=true href=#-7-reinforcement-learning-losses>#</a></h3><h4 id=policy-gradient-loss-reinforce>Policy Gradient Loss (REINFORCE)<a hidden class=anchor aria-hidden=true href=#policy-gradient-loss-reinforce>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_PG = -E[log(œÄ(a|s)) * A(s,a)]
</code></pre><p>Where:</p><ul><li><code>œÄ(a|s)</code> = policy probability of action <code>a</code> given state <code>s</code></li><li><code>A(s,a) = Q(s,a) - V(s)</code> = advantage function</li><li><code>Q(s,a)</code> = action-value function</li><li><code>V(s)</code> = state-value function (baseline)</li></ul><p><strong>Properties:</strong></p><ul><li>Maximizes expected return</li><li>Uses advantage to reduce variance</li><li>On-policy algorithm</li><li>High variance (requires many samples)</li></ul><p><strong>When to use:</strong></p><ul><li>Policy gradient methods (REINFORCE, Actor-Critic)</li><li>Continuous/discrete action spaces</li><li>Need to learn stochastic policies</li></ul><p><strong>Note:</strong> Baseline (V(s)) reduces variance without introducing bias.</p><hr><h4 id=value-function-loss>Value Function Loss<a hidden class=anchor aria-hidden=true href=#value-function-loss>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_V = E[(V(s) - R)^2]
</code></pre><p>Where:</p><ul><li><code>V(s)</code> = predicted state value</li><li><code>R</code> = actual return (discounted sum of rewards)</li></ul><p>For TD learning:</p><pre tabindex=0><code>L_V = E[(V(s) - (r + Œ≥ * V(s&#39;)))^2]
</code></pre><p>Where:</p><ul><li><code>r</code> = immediate reward</li><li><code>Œ≥</code> = discount factor</li><li><code>s'</code> = next state</li></ul><p><strong>Properties:</strong></p><ul><li>Regression loss (typically MSE)</li><li>Learns to predict expected returns</li><li>Used in Actor-Critic, DQN, A3C</li><li>Provides baseline for policy gradient</li></ul><p><strong>When to use:</strong></p><ul><li>Value-based methods (DQN)</li><li>Actor-Critic architectures</li><li>Need to estimate state/action values</li><li>Baseline estimation for policy gradients</li></ul><hr><h4 id=ppo-loss-clipped>PPO Loss (Clipped)<a hidden class=anchor aria-hidden=true href=#ppo-loss-clipped>#</a></h4><p><strong>Formula:</strong></p><pre tabindex=0><code>L_PPO = E[min(r(Œ∏) * A, clip(r(Œ∏), 1-Œµ, 1+Œµ) * A)]
</code></pre><p>Where:</p><ul><li><code>r(Œ∏) = œÄ_Œ∏(a|s) / œÄ_Œ∏_old(a|s)</code> (importance sampling ratio)</li><li><code>A</code> = advantage estimate</li><li><code>Œµ</code> = clipping parameter (typically <code>0.1-0.3</code>)</li></ul><p><strong>Properties:</strong></p><ul><li>Clips policy updates to prevent large changes</li><li>Prevents policy from moving too far from old policy</li><li>More stable than vanilla policy gradient</li><li>State-of-the-art for many RL tasks</li></ul><p><strong>When to use:</strong></p><ul><li>Need stable policy gradient training</li><li>Continuous control tasks</li><li>When sample efficiency matters</li><li>Modern RL applications (robotics, games)</li></ul><p><strong>Advantages:</strong></p><ul><li>Prevents destructive policy updates</li><li>Better sample efficiency</li><li>Easier to tune than TRPO</li><li>Works well with function approximation</li></ul><p><strong>Typical hyperparameters:</strong></p><ul><li><code>Œµ = 0.2</code> (clipping range)</li><li>Learning rate = <code>3e-4</code></li><li>Multiple epochs per batch (typically <code>4-10</code>)</li></ul><hr><h3 id=-8-autoencoder--reconstruction-losses>üü© 8. Autoencoder & Reconstruction Losses<a hidden class=anchor aria-hidden=true href=#-8-autoencoder--reconstruction-losses>#</a></h3><h4 id=81-reconstruction-loss>8.1 Reconstruction Loss<a hidden class=anchor aria-hidden=true href=#81-reconstruction-loss>#</a></h4><p><strong>Formula:</strong></p><p><strong>MSE Reconstruction:</strong></p><pre tabindex=0><code>L_recon_MSE = (1/n) * Œ£(x_i - xÃÇ_i)¬≤
</code></pre><p><strong>L1 Reconstruction:</strong></p><pre tabindex=0><code>L_recon_L1 = (1/n) * Œ£|x_i - xÃÇ_i|
</code></pre><p>Where:</p><ul><li><code>x_i</code> = original input</li><li><code>xÃÇ_i</code> = reconstructed output</li></ul><p><strong>Properties:</strong></p><ul><li>Measures how well the model reconstructs input</li><li>MSE: smooth, penalizes large errors quadratically</li><li>L1: robust to outliers, linear penalty</li><li>Used in standard autoencoders, denoising autoencoders</li></ul><p><strong>When to use:</strong></p><ul><li><strong>MSE:</strong> When input is continuous, normally distributed errors</li><li><strong>L1:</strong> When input has outliers, need robustness</li><li>Standard autoencoders, denoising tasks</li><li>Compression, dimensionality reduction</li></ul><p><strong>Note:</strong> For images, can also use perceptual losses (VGG features) instead of pixel-wise losses.</p><hr><h4 id=82-kl-divergence-vae>8.2 KL Divergence (VAE)<a hidden class=anchor aria-hidden=true href=#82-kl-divergence-vae>#</a></h4><p><strong>Formula:</strong></p><p><strong>VAE Total Loss:</strong></p><pre tabindex=0><code>L_VAE = L_recon + Œ≤ * L_KL
</code></pre><p>Where:</p><pre tabindex=0><code>L_KL = KL(q(z|x) || p(z))
</code></pre><p>For Gaussian prior and posterior:</p><pre tabindex=0><code>L_KL = (1/2) * Œ£(œÉ¬≤ + Œº¬≤ - 1 - log(œÉ¬≤))
</code></pre><p>Where:</p><ul><li><code>q(z|x)</code> = encoder output (posterior): <code>N(Œº, œÉ¬≤)</code></li><li><code>p(z)</code> = prior: <code>N(0, I)</code></li><li><code>Œº, œÉ</code> = encoder outputs (mean and log-variance)</li><li><code>Œ≤</code> = regularization strength (Œ≤-VAE, typically <code>1.0</code>)</li></ul><p><strong>Properties:</strong></p><ul><li>Regularizes latent space to match prior distribution</li><li>Encourages smooth, continuous latent space</li><li>Prevents posterior collapse (encoder ignores input)</li><li>Enables sampling and interpolation in latent space</li></ul><p><strong>When to use:</strong></p><ul><li>Variational Autoencoders (VAEs)</li><li>Need to sample from latent space</li><li>Want smooth latent representations</li><li>Generative modeling with continuous latent variables</li></ul><p><strong>Œ≤-VAE:</strong></p><ul><li><code>Œ≤ > 1</code>: stronger regularization, better disentanglement</li><li><code>Œ≤ &lt; 1</code>: weaker regularization, better reconstruction</li><li><code>Œ≤ = 1</code>: standard VAE</li></ul><p><strong>Common Issues:</strong></p><ul><li><strong>Posterior collapse:</strong> <code>Œ≤</code> too large ‚Üí encoder ignores input</li><li><strong>Blurry reconstructions:</strong> Common with MSE reconstruction</li><li><strong>KL vanishing:</strong> <code>Œ≤</code> too small ‚Üí latent space not regularized</li></ul><hr><h2 id=-summary-quick-reference-guide>üìä Summary: Quick Reference Guide<a hidden class=anchor aria-hidden=true href=#-summary-quick-reference-guide>#</a></h2><h3 id=loss-function-selection-by-task>Loss Function Selection by Task<a hidden class=anchor aria-hidden=true href=#loss-function-selection-by-task>#</a></h3><table><thead><tr><th>Task Type</th><th>Recommended Loss</th><th>Key Considerations</th></tr></thead><tbody><tr><td><strong>Regression</strong></td><td>MSE, MAE, Huber</td><td>MSE for normal errors, MAE for outliers, Huber for balance</td></tr><tr><td><strong>Binary Classification</strong></td><td>Binary Cross-Entropy</td><td>Use with sigmoid activation</td></tr><tr><td><strong>Multi-class Classification</strong></td><td>Categorical Cross-Entropy</td><td>Use with softmax activation</td></tr><tr><td><strong>Imbalanced Classification</strong></td><td>Focal Loss</td><td>Adjust Œ≥ and Œ± for class imbalance</td></tr><tr><td><strong>Image Segmentation</strong></td><td>Dice Loss, IoU Loss, BCE+Dice</td><td>Dice/IoU for overlap, combined for stability</td></tr><tr><td><strong>Language Modeling</strong></td><td>Cross-Entropy (token-level)</td><td>Standard for next-token prediction</td></tr><tr><td><strong>Similarity Learning</strong></td><td>Contrastive Loss, Triplet Loss</td><td>Contrastive for pairs, Triplet for relative distances</td></tr><tr><td><strong>GAN Training</strong></td><td>Wasserstein Loss (WGAN-GP)</td><td>Most stable, use gradient penalty</td></tr><tr><td><strong>VAE</strong></td><td>Reconstruction + KL Divergence</td><td>Balance Œ≤ for reconstruction vs regularization</td></tr><tr><td><strong>Reinforcement Learning</strong></td><td>PPO Loss</td><td>Clipped for stability</td></tr></tbody></table><h3 id=key-properties-to-consider>Key Properties to Consider<a hidden class=anchor aria-hidden=true href=#key-properties-to-consider>#</a></h3><ol><li><strong>Differentiability:</strong> Most losses need to be differentiable for backpropagation</li><li><strong>Robustness:</strong> Some losses (MAE, Huber) are more robust to outliers</li><li><strong>Gradient Behavior:</strong> Smooth gradients (MSE) vs non-smooth (MAE at zero)</li><li><strong>Scale Sensitivity:</strong> Some losses are scale-dependent, others are scale-invariant</li><li><strong>Class Imbalance:</strong> Focal Loss, Dice Loss handle imbalance better</li><li><strong>Direct Optimization:</strong> Dice/IoU directly optimize evaluation metrics</li></ol><h3 id=common-patterns>Common Patterns<a hidden class=anchor aria-hidden=true href=#common-patterns>#</a></h3><ul><li><strong>Combined Losses:</strong> Often combine multiple losses (e.g., BCE + Dice, Reconstruction + KL)</li><li><strong>Weighted Losses:</strong> Use weighting factors (Œ±, Œ≤) to balance different objectives</li><li><strong>Adaptive Losses:</strong> Some losses adapt during training (e.g., curriculum learning)</li><li><strong>Task-Specific:</strong> Choose loss that matches your evaluation metric when possible</li></ul><h3 id=best-practices>Best Practices<a hidden class=anchor aria-hidden=true href=#best-practices>#</a></h3><ol><li><strong>Match Loss to Metric:</strong> If evaluating with IoU, use IoU loss</li><li><strong>Handle Edge Cases:</strong> Add epsilon to logarithms, handle division by zero</li><li><strong>Normalize Appropriately:</strong> Consider batch normalization, loss normalization</li><li><strong>Monitor Training:</strong> Watch for vanishing/exploding gradients</li><li><strong>Experiment:</strong> Try different losses and combinations for your specific problem</li></ol></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://rapternmn.github.io/>Rapternmn Blog</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>