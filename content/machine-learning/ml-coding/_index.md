+++
title = "ML Coding"
description = "Hands-on implementations of core machine learning algorithms from scratch. Learn to code linear regression, logistic regression, decision trees, clustering algorithms, and more using Python and NumPy."
weight = 3
+++

This section provides hands-on implementations of machine learning algorithms from scratch. Learn to code core ML algorithms using Python and NumPy, understanding the inner workings of each algorithm.

---

## ðŸ“– Topics

- **[Linear Regression Implementation]({{< ref "1-Linear_Regression_Implementation.md" >}})** - Implement linear regression from scratch, gradient descent, and optimization
- **[Logistic Regression Implementation]({{< ref "2-Logistic_Regression_Implementation.md" >}})** - Implement logistic regression, sigmoid function, and binary classification
- **[Decision Tree Implementation]({{< ref "3-Decision_Tree_Implementation.md" >}})** - Build decision trees from scratch, entropy, information gain, and tree construction
- **[Clustering Algorithms Implementation]({{< ref "4-Clustering_Algorithms_Implementation.md" >}})** - Implement K-means, hierarchical clustering, and clustering algorithms
- **[Naive Bayes Implementation]({{< ref "5-Naive_Bayes_Implementation.md" >}})** - Implement Naive Bayes classifier for text classification and probability estimation
- **[KNN Implementation]({{< ref "6-KNN_Implementation.md" >}})** - Implement K-Nearest Neighbors algorithm, distance metrics, and classification
- **[SVM Implementation]({{< ref "7-SVM_Implementation.md" >}})** - Implement Support Vector Machines, kernels, and optimization
- **[Random Forest Implementation]({{< ref "8-Random_Forest_Implementation.md" >}})** - Build random forests from scratch, ensemble methods, and bagging
- **[Gradient Boosting Implementation]({{< ref "9-Gradient_Boosting_Implementation.md" >}})** - Implement gradient boosting, XGBoost concepts, and boosting algorithms
- **[PCA Implementation]({{< ref "10-PCA_Implementation.md" >}})** - Implement Principal Component Analysis, dimensionality reduction, and eigen decomposition
- **[Neural Network Basics]({{< ref "11-Neural_Network_Basics.md" >}})** - Build neural networks from scratch, backpropagation, and activation functions
- **[CNN Implementation]({{< ref "12-CNN_Implementation.md" >}})** - Implement Convolutional Neural Networks, convolutions, pooling, and image processing
- **[RNN/LSTM Implementation]({{< ref "13-RNN_LSTM_Implementation.md" >}})** - Implement Recurrent Neural Networks and LSTM for sequence modeling
- **[Evaluation Metrics Implementation]({{< ref "14-Evaluation_Metrics_Implementation.md" >}})** - Implement evaluation metrics from scratch: accuracy, precision, recall, F1, ROC-AUC

---

## ðŸŽ¯ Learning Path

1. **Start with Linear Models** - Linear regression and logistic regression
2. **Learn Tree-Based Algorithms** - Decision trees and random forests
3. **Explore Clustering** - K-means and clustering algorithms
4. **Study Advanced Algorithms** - SVM, gradient boosting, neural networks
5. **Implement Deep Learning** - CNNs, RNNs, and neural networks
6. **Master Evaluation** - Implement evaluation metrics

---

## ðŸ’¡ Key Concepts

- **Algorithm Implementation**: Code algorithms from scratch to understand them deeply
- **NumPy**: Use NumPy for numerical computations
- **Mathematical Foundations**: Understand the math behind each algorithm
- **Optimization**: Implement optimization algorithms (gradient descent, etc.)
- **Evaluation**: Code evaluation metrics to understand model assessment

---

## ðŸ”— Related Sections

- **[ML Fundamentals]({{< ref "../ml-fundamentals/_index.md" >}})** - ML concepts and theory
- **[Data Science]({{< ref "../data-science/_index.md" >}})** - Data science workflows and techniques
- **[MLOps]({{< ref "../mlops/_index.md" >}})** - Production ML systems
